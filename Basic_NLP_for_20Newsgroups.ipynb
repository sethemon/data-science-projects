{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f9547e",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier with basic NLP techniques\n",
    "The dataset considered is the famous “20 Newsgoup” data set (Original 20 Newsgroups data set). Dataset can be found at the following link: http://qwone.com/~jason/20Newsgroups/ \n",
    "\n",
    "**Dataset used here**: https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html\n",
    "\n",
    "\n",
    "\n",
    "1. Load the data set and import necessary libraries.\n",
    "2. Extract features from text files. Each unique word in the document can be considered as a feature.\n",
    "3. Compute TF and TF-IDF factors.\n",
    "4. Demonstrate text classification by using Naive Bayes classifier(build a NBclassifier in scikit). Train the NB classifier on the data provided.\n",
    "5. Build a pipeline of TF-IDF and NB classification function.\n",
    "6. Test the performance of the NB classifier on the test set.\n",
    "7. Remove the stop-words and  build a pipeline of tf-idf and classification function. Now compare the performance with the previous process.(i.e without stopword removal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298e1dc",
   "metadata": {},
   "source": [
    "!pip install gensim contractions bs4 plotly wordcloud spacy python-Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19385303",
   "metadata": {},
   "source": [
    "### Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf80067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata                          # Import Regex, string and unicodedata\n",
    "import contractions                                     # Import contractions library\n",
    "from bs4 import BeautifulSoup                           # Import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np                                      # Import numpy\n",
    "import pandas as pd                                     # Import pandas\n",
    "import nltk                                             # Import Natural Language Tool-Kit\n",
    "\n",
    "## UN-COMMENT while running for the FIRST time\n",
    "# nltk.download('stopwords')                            # Download Stopwords\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords                       # Import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize  # Import Tokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer         # Import Lemmatizer\n",
    "\n",
    "## Import visualization library\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Importing Multinomial Naive Bayes as asked\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# Import Scikit-learn utilities for data split and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, learning_curve\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "# Importing Scikit-learn Pipelines\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Importing TfidfVectorizer to convert text data to numbers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.parsing import strip_tags, strip_numeric, strip_multiple_whitespaces, stem_text, strip_punctuation, \\\n",
    "    remove_stopwords, preprocess_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4775c6",
   "metadata": {},
   "source": [
    "### Loading the dataset (from sklearn.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd7e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using the dataset from sklearn library \n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa96e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINset shape : (11314,), Target shape: (11314,)\n",
      "TESTset shape : (7532,), Target shape: (7532,)\n",
      "\n",
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# TRAIN set\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "# Trainset size\n",
    "print(f\"TRAINset shape : {newsgroups_train.filenames.shape}, Target shape: {newsgroups_train.target.shape}\")\n",
    "# pprint(list(newsgroups_train.target_names))\n",
    "\n",
    "# TEST set\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "# Testset size\n",
    "print(f\"TESTset shape : {newsgroups_test.filenames.shape}, Target shape: {newsgroups_test.target.shape}\")\n",
    "# pprint(list(newsgroups_test.target_names))\n",
    "print()\n",
    "categories = list(newsgroups_train.target_names)\n",
    "pprint(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5774cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dataframe for TRAIN dataset\n",
    "news_train_df = pd.DataFrame(newsgroups_train.data, columns=['raw_data'])\n",
    "# adding a target column\n",
    "news_train_df['target'] = newsgroups_train.target\n",
    "# adding length of data for visualizations\n",
    "news_train_df['length'] = news_train_df['raw_data'].apply(len)\n",
    "\n",
    "news_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05200b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making a dataframe for TEST dataset\n",
    "news_test_df = pd.DataFrame(newsgroups_test.data, columns=['raw_data'])\n",
    "# adding a target column\n",
    "news_test_df['target'] = newsgroups_test.target\n",
    "# adding length of data for visualizations\n",
    "news_test_df['length'] = news_test_df['raw_data'].apply(len)\n",
    "\n",
    "news_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BarPlot of Target labels\n",
    "sns.barplot(x='target', y='length', data=news_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4695fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BarPlot of Target labels\n",
    "sns.barplot(x='target', y='length', data=news_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3bf103",
   "metadata": {},
   "source": [
    "### preprocess using gensim.parsing\n",
    "\n",
    "We have used gensim preprocessing pipeline here, as first attempt\n",
    "\n",
    "* NOT REMOVING STOPWORDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c556304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text : \n",
      "From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\n",
      "Subject: Need info on 88-89 Bonneville\n",
      "Organization: University at Buffalo\n",
      "Lines: 10\n",
      "News-Software: VAX/VMS VNEWS 1.41\n",
      "Nntp-Posting-Host: ubvmsd.cc.buffalo.edu\n",
      "\n",
      "\n",
      " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "\n",
      "\t\t\tNeil Gandler\n",
      "\n",
      "Cleaned text : \n",
      "from vmbk ubvmsd cc buffalo edu neil gandler subject need info on bonneville organization university at buffalo lines news software vax vms vnews nntp posting host ubvmsd cc buffalo edu am little confused on all of the models of the bonnevilles have heard of the le se lse sse ssei could someone tell me the differences are far as features or performance am also curious to know what the book value is for prefereably the model and how much less than book value can you usually get them for in other words how much are they in demand this time of year have heard that the mid spring early summer is the best time to buy neil gandler\n"
     ]
    }
   ],
   "source": [
    "# ref: https://www.kaggle.com/venkatkrishnan/gensim-text-mining-techniques\n",
    "\n",
    "transform_to_lower = lambda s: s.lower()\n",
    "\n",
    "remove_single_char = lambda s: re.sub(r'\\s+\\w{1}\\s+', ' ', s)\n",
    "\n",
    "# Filters to be executed in pipeline\n",
    "CLEAN_FILTERS = [strip_tags,\n",
    "                strip_numeric,\n",
    "                strip_punctuation, \n",
    "                strip_multiple_whitespaces, \n",
    "                transform_to_lower,\n",
    "#                 remove_stopwords,   # NOT REMOVING STOPWORDS at first go\n",
    "                remove_single_char]\n",
    "\n",
    "\n",
    "# Method does the filtering of all the unrelevant text elements\n",
    "def cleaning_text(document):\n",
    "    # Invoking gensim.parsing.preprocess_string method with set of filters\n",
    "    processed_words = preprocess_string(document, CLEAN_FILTERS)\n",
    "    return ' '.join(processed_words)\n",
    "\n",
    "\n",
    "print(f\"Original text : \\n---------------------------------\\n{news_test_df['raw_data'][0]}\")\n",
    "print(f\"Cleaned text : \\n---------------------------------\\n{cleaning_text(news_test_df['raw_data'][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5daddffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding processed/cleaned data to a new column\n",
    "news_train_df['clean_data'] = news_train_df['raw_data'].apply(cleaning_text)\n",
    "# adding length of data for visualizations\n",
    "news_train_df['clean_length'] = news_train_df['clean_data'].apply(len)\n",
    "\n",
    "\n",
    "news_test_df['clean_data'] = news_test_df['raw_data'].apply(cleaning_text)\n",
    "# adding length of data for visualizations\n",
    "news_test_df['clean_length'] = news_test_df['clean_data'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ebb941",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174082a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85086\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer().fit(news_train_df['clean_data'])\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac641ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from</td>\n",
       "      <td>27040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lerxst</td>\n",
       "      <td>41661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wam</td>\n",
       "      <td>80022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>umd</td>\n",
       "      <td>76387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edu</td>\n",
       "      <td>21442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>where</td>\n",
       "      <td>80815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>my</td>\n",
       "      <td>49039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thing</td>\n",
       "      <td>73401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subject</td>\n",
       "      <td>70632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what</td>\n",
       "      <td>80767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Words  Count\n",
       "0     from  27040\n",
       "1   lerxst  41661\n",
       "2      wam  80022\n",
       "3      umd  76387\n",
       "4      edu  21442\n",
       "5    where  80815\n",
       "6       my  49039\n",
       "7    thing  73401\n",
       "8  subject  70632\n",
       "9     what  80767"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = bow_transformer.vocabulary_.items()\n",
    "data = list(result)\n",
    "term_freq_df = pd.DataFrame(data)\n",
    "term_freq_df.columns =['Words', 'Count']\n",
    "term_freq_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960f08b",
   "metadata": {},
   "source": [
    "# Computing Tf-Idf for the given data\n",
    "\n",
    "- t — term (word)\n",
    "- d — document (set of words)\n",
    "- N — count of corpus (size)\n",
    "- corpus — the total document set\n",
    "\n",
    "## Term Frequency :\n",
    "The number of times a term occurs in a document is called its term frequency.\n",
    "The weight of a term that occurs in a document is simply proportional to the term frequency.\n",
    "#### tf(t,d) = count of {term} in {doc} / number of words in {doc}\n",
    "\n",
    "\n",
    "## Inverse Document Frequency : \n",
    "IDF is the inverse of the document frequency which measures the informativeness of term t. When we calculate IDF, it will be very low for the most occurring words such as stop words (because stop words such as “is” is present in almost all of the documents, and N/df will give a very low value to that word). This finally gives what we want, a relative weightage.\n",
    "#### idf(t) = log( {N} / ({doc freq} + 1)) \n",
    "\n",
    "\n",
    "### Formula:           tf-idf(t, d) = tf(t, d) * log(N/(df + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa8fc3",
   "metadata": {},
   "source": [
    "Calculating the TF-IDF Scores of 25 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e26204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                TF-IDF\n",
      "car           0.388991\n",
      "lerxst        0.362351\n",
      "wam           0.264854\n",
      "umd           0.216329\n",
      "tellme        0.181176\n",
      "bricklin      0.171154\n",
      "rac           0.159623\n",
      "funky         0.159623\n",
      "was           0.148913\n",
      "this          0.147964\n",
      "enlighten     0.137357\n",
      "bumper        0.136004\n",
      "neighborhood  0.134738\n",
      "the           0.125813\n",
      "doors         0.118028\n",
      "maryland      0.111996\n",
      "production    0.111057\n",
      "specs         0.111057\n",
      "sports        0.110694\n",
      "where         0.110630\n",
      "anyone        0.105241\n",
      "door          0.102800\n",
      "park          0.101632\n",
      "separate      0.101073\n",
      "il            0.099690\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(news_train_df['clean_data'])\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b29a971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (11314, 85086)\n",
      "Amount of Non-Zero occurences:  1652974\n"
     ]
    }
   ],
   "source": [
    "messages_bow = bow_transformer.transform(news_train_df['clean_data'])\n",
    "print('Shape of Sparse Matrix: ', messages_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', messages_bow.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c356942e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 85086)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "\n",
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a389fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = news_train_df[\"clean_data\"]\n",
    "X_test = news_test_df['clean_data']\n",
    "y_train = news_train_df[\"target\"] \n",
    "y_test = news_test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "663e344e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 5.99484250e-04, 3.59381366e-03, 2.15443469e-02,\n",
       "       1.29154967e-01, 7.74263683e-01, 4.64158883e+00, 2.78255940e+01,\n",
       "       1.66810054e+02, 1.00000000e+03])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-4, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356a8ef",
   "metadata": {},
   "source": [
    "Using TF-IDF Transformer with Count Vectorizer gives the TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e29d5ba4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters \n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'classifier': MultinomialNB(alpha=0.021544346900318846, class_prior=None, fit_prior=True), 'classifier__alpha': 0.021544346900318846}\n",
      "0.9134694272869002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create first pipeline for base without reducing features.\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = [\n",
    "    {'classifier' : [MultinomialNB()],\n",
    "     'classifier__alpha' : np.logspace(-4, 3, 10)   \n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"# Tuning hyper-parameters \")\n",
    "mnb_clf = GridSearchCV(pipeline, param_grid = param_grid, cv=10, verbose=1, refit=True, n_jobs=-1, scoring='accuracy')\n",
    "mnb_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(mnb_clf.best_params_)\n",
    "print(mnb_clf.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ce02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = mnb_clf.best_estimator_\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_true, y_pred = y_test, best.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(f'Accuracy of MultinomialNB classifier on test set: {accuracy_score(y_true, y_pred)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd333edc",
   "metadata": {},
   "source": [
    "We achieved 83.4% accuracy on the test set without Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ee2a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(best, X_test, y_test,\n",
    "                                 display_labels=mnb_clf.classes_,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "    print(\"===================================================================================\")\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "    print()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e046b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_names = categories\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "plot_confusion_matrix(best, X_test, y_test,\n",
    "                      display_labels=target_names,\n",
    "                      cmap=plt.cm.Blues, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20c01bd",
   "metadata": {},
   "source": [
    "## Recreating dataset with STOPWORD removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a863205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text : \n",
      "-------------------------------\n",
      "From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\n",
      "Subject: Need info on 88-89 Bonneville\n",
      "Organization: University at Buffalo\n",
      "Lines: 10\n",
      "News-Software: VAX/VMS VNEWS 1.41\n",
      "Nntp-Posting-Host: ubvmsd.cc.buffalo.edu\n",
      "\n",
      "\n",
      " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "\n",
      "\t\t\tNeil Gandler\n",
      "\n",
      "Cleaned text : \n",
      "---------------------------------\n",
      "vmbk ubvmsd cc buffalo edu neil gandler subject need info bonneville organization university buffalo lines news software vax vms vnews nntp posting host ubvmsd cc buffalo edu little confused models bonnevilles heard le se lse sse ssei tell differences far features performance curious know book value prefereably model book value usually words demand time year heard mid spring early summer best time buy neil gandler\n"
     ]
    }
   ],
   "source": [
    "transform_to_lower = lambda s: s.lower()\n",
    "\n",
    "remove_single_char = lambda s: re.sub(r'\\s+\\w{1}\\s+', ' ', s)\n",
    "\n",
    "# Filters to be executed in pipeline\n",
    "CLEAN_FILTERS = [strip_tags,\n",
    "                strip_numeric,\n",
    "                strip_punctuation, \n",
    "                strip_multiple_whitespaces, \n",
    "                transform_to_lower,\n",
    "                remove_stopwords,   # REMOVING STOPWORDS at second go\n",
    "                remove_single_char]\n",
    "\n",
    "\n",
    "# Method does the filtering of all the unrelevant text elements\n",
    "def cleaning_text(document):\n",
    "    # Invoking gensim.parsing.preprocess_string method with set of filters\n",
    "    processed_words = preprocess_string(document, CLEAN_FILTERS)\n",
    "    return ' '.join(processed_words)\n",
    "\n",
    "\n",
    "print(f\"Original text : \\n-------------------------------\\n{news_test_df['raw_data'][0]}\")\n",
    "print(f\"Cleaned text : \\n---------------------------------\\n{cleaning_text(news_test_df['raw_data'][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9428f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding processed/cleaned data to a new column\n",
    "news_train_df['cleaned_stopword_data'] = news_train_df['raw_data'].apply(cleaning_text)\n",
    "# adding length of data for visualizations\n",
    "news_train_df['cleaned_stop_length'] = news_train_df['cleaned_stopword_data'].apply(len)\n",
    "\n",
    "\n",
    "news_test_df['cleaned_stopword_data'] = news_test_df['raw_data'].apply(cleaning_text)\n",
    "# adding length of data for visualizations\n",
    "news_test_df['cleaned_stop_length'] = news_test_df['cleaned_stopword_data'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198eefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15d74a",
   "metadata": {},
   "source": [
    "We have added a column \"cleaned_stop_length\" to show how the no. of words reduces after the removal of stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513c89a",
   "metadata": {},
   "source": [
    "Next we divide the dataset into train and test with the cleaned stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6986f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = news_train_df[\"cleaned_stopword_data\"]\n",
    "X_test2 = news_test_df['cleaned_stopword_data']\n",
    "y_train = news_train_df[\"target\"] \n",
    "y_test = news_test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db685313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create first pipeline for base without reducing features.\n",
    "# pipeline = Pipeline([\n",
    "#     ('bow', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=85000)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = [\n",
    "    {'classifier' : [MultinomialNB()],\n",
    "     'classifier__alpha' : np.logspace(-5, 3, 8)   \n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"# Tuning hyper-parameters \")\n",
    "mnb_clf2 = GridSearchCV(pipeline, param_grid = param_grid, cv=10, verbose=1, refit=True, n_jobs=-1, scoring='accuracy')\n",
    "mnb_clf2.fit(X_train2, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(mnb_clf2.best_params_)\n",
    "print(mnb_clf2.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de886dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best2 = mnb_clf.best_estimator_\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_true, y_pred = y_test, best.predict(X_test2)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(f'Accuracy of MultinomialNB classifier on test set: {accuracy_score(y_true, y_pred)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace255d",
   "metadata": {},
   "source": [
    "We can see that after stopword removal, the accuracy only improved by a very small percentage rather than a significant change. This shows that we have to try some other preprocessing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f371fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = categories\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "plot_confusion_matrix(best2, X_test2, y_test,\n",
    "                      display_labels=target_names,\n",
    "                      cmap=plt.cm.Blues, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afddeb2",
   "metadata": {},
   "source": [
    "## Performing some NLP on same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f636751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging both train and test datasets\n",
    "newsdf_whole = pd.concat([news_train_df, news_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0731258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['does', 'each', 'do', 'its', 'now', 'here', 'or', 'my', 'aren', 'there', 'own', 'will', 'thru', 'too', 'at', 'against', 'themselves', 'was', 'nor', 'ourselves', 'm', 'for', 'are', 'below', 'from', 'why', 'some', 'that', 'because', 'most', 'lmao', 'her', 'after', 'ur', 'an', 'under', 'yourself', 't', 'we', 're', 'she', 'he', 'them', 'they', 'theirs', 'until', 'into', 've', 'couldn', 'plz', 'your', 'again', 'coz', 'whom', 'what', 'which', 'were', 'as', 'ours', 'same', 'and', \"you're\", 'had', 'a', 'yours', 'frm', 'herself', 'doing', 'idk', 'in', 'd', 'other', 'such', 'himself', 'being', 'agn', 'who', 'over', \"you've\", 'those', 'more', 'these', 'll', 'itself', 'but', 'it', 'when', 'above', 'his', 'on', 'both', 'only', 'him', 'once', 'how', \"aren't\", 'about', 'then', 'can', 'be', 'while', 'by', 'this', 'bcoz', 'hs', 'you', 'if', 'few', 'just', 'shud', 'our', 'hmm', 'o', 'did', 'during', 'before', 'gonna', 'lol', 'sup', 'myself', 'i', 'where', 'me', 'up', 'hers', 'fr', 'out', 'should', 'am', 'hav', 'between', 'very', 'further', 'than', 'whr', 'ain', 'cum', 'hw', 'thr', 'of', 'cn', 'u', 'ttyl', 'off', 'yourselves', 'through', 'to', 'so', 'with', 'been', 'their', 'has', 'any', 'cya', 'don', 'is', 'have', 'all', 'having', 'the', 'whn']\n"
     ]
    }
   ],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "# print(stopword_list)\n",
    "\n",
    "## Set custom stop-word's list as not, couldn't etc. words matter in \"SMS\", so not removing them from original data.\n",
    "custom_excludelist = [\"couldn't\",'didn',\"don't\",\"didn't\",'doesn',\"doesn't\",'down','hadn',\"hadn't\",'hasn',\n",
    "                      \"hasn't\",'haven',\"haven't\",'isn',\"isn't\",\"it's\",'ma','mightn',\"mightn't\",'mustn',\"no\",\"not\",\n",
    "                      \"mustn't\",'needn',\"needn't\",'shan',\"shan't\",\"she's\",'shouldn',\"should've\",\"shouldn't\",'s',\n",
    "                      \"that'll\",'wasn',\"wasn't\",'weren',\"weren't\",'won',\"won't\",'wouldn',\"wouldn't\",\"you'd\",\"you'll\",\"y\"]\n",
    "\n",
    "## Add custom stop-word's list to stopwords for SMS (short) language \n",
    "custom_new_stopwords = [\"thru\",\"whr\",\"whn\",\"hw\",\"gonna\",\"u\",\"plz\",\"hmm\",\"cn\",\"ur\",\"cya\",\"idk\",\"ttyl\",\n",
    "                        \"lol\",\"lmao\",\"sup\",\"coz\",\"bcoz\",\"cum\",\"fr\",\"frm\",\"shud\",\"hs\",\"agn\",\"hav\",\"thr\"]\n",
    "\n",
    "stoplist = set(set(stopword_list) - set(custom_excludelist)) \n",
    "stoplist = list(stoplist.union(custom_new_stopwords))\n",
    "print(stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "newsdf_whole['raw_news'] = newsdf_whole['raw_data'].apply(lambda x: replace_contractions(x))\n",
    "newsdf_whole.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "185f8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', ' ', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stoplist:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def lemmatize_list(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(lemmatizer.lemmatize(word, pos='v'))\n",
    "    return new_words\n",
    "\n",
    "def preprocess(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = lemmatize_list(words)\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dee365",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Tokenization of SMS data for pre-processing\n",
    "newsdf_whole['tokenized_news'] = newsdf_whole.apply(lambda row: nltk.word_tokenize(row['raw_news']), axis=1)\n",
    "\n",
    "## Pre-process each row\n",
    "newsdf_whole['cleaned_news'] = newsdf_whole.apply(lambda row: preprocess(row['tokenized_news']), axis=1)\n",
    "\n",
    "## Remove pre-processing column name 'cleaned_sms'\n",
    "newsdf_whole = newsdf_whole.drop(['tokenized_news', 'raw_news'], axis=1)\n",
    "newsdf_whole.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce5bd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(newsdf_whole, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a21e851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13192,), (13192,), (5654,), (5654,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['cleaned_news'].shape, train['target'].shape, test['cleaned_news'].shape, test['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5fb33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = train['cleaned_news']\n",
    "y_train = train['target']\n",
    "X_test3 = test['cleaned_news']\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dcf70bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters \n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'classifier': MultinomialNB(alpha=0.026826957952797246, class_prior=None, fit_prior=True), 'classifier__alpha': 0.026826957952797246}\n",
      "0.9025917821122521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create first pipeline for base without reducing features.\n",
    "# pipeline = Pipeline([\n",
    "#     ('bow', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=60000)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = [\n",
    "    {'classifier' : [MultinomialNB()],\n",
    "     'classifier__alpha' : np.logspace(-5, 3, 8)   \n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"# Tuning hyper-parameters \")\n",
    "mnb_clf3 = GridSearchCV(pipeline, param_grid = param_grid, cv=10, verbose=1, refit=True, n_jobs=-1, scoring='accuracy')\n",
    "mnb_clf3.fit(X_train3, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(mnb_clf3.best_params_)\n",
    "print(mnb_clf3.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fbefe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       238\n",
      "           1       0.80      0.85      0.82       267\n",
      "           2       0.85      0.83      0.84       309\n",
      "           3       0.79      0.87      0.83       307\n",
      "           4       0.92      0.87      0.89       293\n",
      "           5       0.94      0.90      0.92       288\n",
      "           6       0.86      0.84      0.85       287\n",
      "           7       0.92      0.94      0.93       302\n",
      "           8       0.97      0.97      0.97       299\n",
      "           9       0.95      0.97      0.96       303\n",
      "          10       0.96      0.97      0.97       276\n",
      "          11       0.95      0.95      0.95       293\n",
      "          12       0.91      0.89      0.90       308\n",
      "          13       0.95      0.93      0.94       301\n",
      "          14       0.93      0.97      0.95       272\n",
      "          15       0.92      0.94      0.93       298\n",
      "          16       0.94      0.96      0.95       302\n",
      "          17       0.98      0.98      0.98       293\n",
      "          18       0.94      0.94      0.94       232\n",
      "          19       0.93      0.74      0.82       186\n",
      "\n",
      "    accuracy                           0.91      5654\n",
      "   macro avg       0.91      0.91      0.91      5654\n",
      "weighted avg       0.91      0.91      0.91      5654\n",
      "\n",
      "\n",
      "Accuracy of MultinomialNB classifier on test set: 0.9136894234170498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best3 = mnb_clf3.best_estimator_\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_true, y_pred = y_test, best3.predict(X_test3)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print(f'Accuracy of MultinomialNB classifier on test set: {accuracy_score(y_true, y_pred)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6d15a",
   "metadata": {},
   "source": [
    "#### We can see that after some NLP preprocessing, the classification accuracy improved by a good percentage. [83% --> 91%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f367c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = categories\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "plot_confusion_matrix(best3, X_test3, y_test,\n",
    "                      display_labels=target_names,\n",
    "                      cmap=plt.cm.Blues, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665f26d",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "    \n",
    "Stopword removal improves the model accuracy, but specific preprocessing measures are needed to be taken (based on our dataset) and then only model accuracy improves. Here we saw that some NLP techniques improves the performance, rather than just stopword removal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
